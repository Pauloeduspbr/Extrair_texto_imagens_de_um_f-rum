# EXTRATOR COM SELE√á√ÉO DE P√ÅGINAS - RANGE CUSTOMIZ√ÅVEL
import subprocess
import sys
import os

def install_packages():
    """Install required packages"""
    required_packages = ['selenium', 'beautifulsoup4', 'webdriver-manager', 'requests']
    
    for package in required_packages:
        try:
            if package == 'beautifulsoup4':
                __import__('bs4')
            elif package == 'webdriver-manager':
                __import__('webdriver_manager')
            else:
                __import__(package)
            print(f"‚úÖ {package} j√° est√° instalado")
        except ImportError:
            print(f"üì¶ Instalando {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
            print(f"‚úÖ {package} instalado com sucesso!")

print("üîß Verificando e instalando depend√™ncias...")
install_packages()

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import json
import time
import re
import requests
from urllib.parse import urljoin, urlparse, parse_qs
import os
from datetime import datetime

# --- Configura√ß√µes ---
THREAD_URL = 'https://www.forexfactory.com/thread/592890-a-very-simple-system-trade-with-arrow'
OUTPUT_DIR = 'topico_completo'
IMAGES_DIR = 'imagens_por_pagina'
USERNAME = 'user'
PASSWORD = 'passwd'

def criar_estrutura_diretorios():
    """Cria estrutura de diret√≥rios organizados"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, 'json_por_pagina'), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, 'imagens_por_pagina'), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, 'resumos'), exist_ok=True)
    print(f"üìÅ Estrutura criada em: {OUTPUT_DIR}/")

def detectar_total_paginas(soup):
    """Detecta o n√∫mero total de p√°ginas do t√≥pico"""
    try:
        seletores_paginacao = [
            '.pagination a',
            '.pagelinks a',
            'td.alt1 a[href*="page"]',
            'div[class*="pagination"] a',
            'span[class*="pagination"] a'
        ]
        
        total_paginas = 1
        
        for seletor in seletores_paginacao:
            links_pagina = soup.select(seletor)
            if links_pagina:
                for link in links_pagina:
                    href = link.get('href', '')
                    texto = link.get_text().strip()
                    
                    if 'page=' in href:
                        try:
                            parsed = urlparse(href)
                            query_params = parse_qs(parsed.query)
                            if 'page' in query_params:
                                pagina = int(query_params['page'][0])
                                total_paginas = max(total_paginas, pagina)
                        except:
                            pass
                    
                    if texto.isdigit():
                        try:
                            pagina = int(texto)
                            total_paginas = max(total_paginas, pagina)
                        except:
                            pass
                
                if total_paginas > 1:
                    break
        
        if total_paginas == 1:
            last_links = soup.select('a[title*="Last"], a[href*="lastpost"], a[title*="√öltima"]')
            for link in last_links:
                href = link.get('href', '')
                if 'page=' in href:
                    try:
                        parsed = urlparse(href)
                        query_params = parse_qs(parsed.query)
                        if 'page' in query_params:
                            total_paginas = int(query_params['page'][0])
                            break
                    except:
                        pass
        
        return max(total_paginas, 1)
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao detectar p√°ginas: {e}")
        return 1

def solicitar_range_paginas(total_disponivel):
    """Solicita ao usu√°rio o range de p√°ginas a extrair"""
    
    print(f"\n" + "="*60)
    print(f"üìä TOTAL DE P√ÅGINAS DISPON√çVEIS: {total_disponivel}")
    print(f"="*60)
    
    print(f"\nüéØ OP√á√ïES DE EXTRA√á√ÉO:")
    print(f"1Ô∏è‚É£  Extrair uma quantidade espec√≠fica (ex: 15, 100)")
    print(f"2Ô∏è‚É£  Extrair um range de p√°ginas (ex: 1-10, 5-25)")
    print(f"3Ô∏è‚É£  Extrair TODAS as p√°ginas ({total_disponivel} p√°ginas)")
    
    while True:
        escolha = input(f"\n‚ñ∂Ô∏è  Escolha uma op√ß√£o (1/2/3): ").strip()
        
        if escolha == '1':
            # Quantidade espec√≠fica
            while True:
                try:
                    quantidade = input(f"\nüìù Quantas p√°ginas extrair? (1-{total_disponivel}): ").strip()
                    quantidade = int(quantidade)
                    
                    if 1 <= quantidade <= total_disponivel:
                        pagina_inicio = 1
                        pagina_fim = quantidade
                        
                        print(f"\n‚úÖ Configurado: P√°ginas 1 at√© {quantidade}")
                        return pagina_inicio, pagina_fim
                    else:
                        print(f"‚ùå Digite um n√∫mero entre 1 e {total_disponivel}")
                        
                except ValueError:
                    print(f"‚ùå Digite um n√∫mero v√°lido")
        
        elif escolha == '2':
            # Range customizado
            while True:
                try:
                    range_input = input(f"\nüìù Digite o range (ex: 1-10, 5-25): ").strip()
                    
                    if '-' in range_input:
                        inicio, fim = range_input.split('-')
                        pagina_inicio = int(inicio.strip())
                        pagina_fim = int(fim.strip())
                        
                        if 1 <= pagina_inicio <= pagina_fim <= total_disponivel:
                            quantidade = pagina_fim - pagina_inicio + 1
                            print(f"\n‚úÖ Configurado: P√°ginas {pagina_inicio} at√© {pagina_fim} ({quantidade} p√°ginas)")
                            return pagina_inicio, pagina_fim
                        else:
                            print(f"‚ùå Range inv√°lido. Use valores entre 1 e {total_disponivel}")
                    else:
                        print(f"‚ùå Use o formato: inicio-fim (ex: 1-10)")
                        
                except ValueError:
                    print(f"‚ùå Digite um range v√°lido")
        
        elif escolha == '3':
            # Todas as p√°ginas
            pagina_inicio = 1
            pagina_fim = total_disponivel
            
            confirmacao = input(f"\n‚ö†Ô∏è  Extrair TODAS as {total_disponivel} p√°ginas? (s/N): ").strip().lower()
            if confirmacao.startswith('s'):
                print(f"\n‚úÖ Configurado: TODAS as {total_disponivel} p√°ginas")
                return pagina_inicio, pagina_fim
            else:
                print(f"\n‚ùå Cancelado. Escolha novamente:")
                continue
        else:
            print(f"‚ùå Op√ß√£o inv√°lida. Digite 1, 2 ou 3")

def construir_url_pagina(base_url, numero_pagina):
    """Constr√≥i URL para uma p√°gina espec√≠fica"""
    if numero_pagina == 1:
        return base_url
    
    if '?' in base_url:
        return f"{base_url}&page={numero_pagina}"
    else:
        return f"{base_url}?page={numero_pagina}"

def criar_sessao_com_cookies(driver):
    """Cria sess√£o requests com cookies do Selenium"""
    session = requests.Session()
    
    cookies = driver.get_cookies()
    for cookie in cookies:
        session.cookies.set(cookie['name'], cookie['value'])
    
    session.headers.update({
        'User-Agent': driver.execute_script("return navigator.userAgent;"),
        'Referer': driver.current_url
    })
    
    return session

def extrair_conteudo_post(post_elemento):
    """Extrai conte√∫do completo do post"""
    elem_mensagem = post_elemento.select_one('div[id*="post_message_"]')
    if elem_mensagem:
        conteudo_bruto = elem_mensagem.get_text(separator='\n', strip=True)
    else:
        for seletor in ['.threadpost-content__message', '.post-content']:
            elem = post_elemento.select_one(seletor)
            if elem:
                conteudo_bruto = elem.get_text(separator='\n', strip=True)
                break
        else:
            conteudo_bruto = post_elemento.get_text(separator='\n', strip=True)
    
    linhas = conteudo_bruto.split('\n')
    linhas_limpas = []
    
    skip_phrases = [
        'view profile', 'send message', 'private message', 'add to ignore list',
        'joined:', 'posts:', 'location:', 'reputation:', 'last online:',
        'edit post', 'quote post', 'multi-quote', 'quick reply'
    ]
    
    for linha in linhas:
        linha = linha.strip()
        if linha and len(linha) > 2:
            linha_lower = linha.lower()
            if not any(skip in linha_lower for skip in skip_phrases):
                if not (re.match(r'^[A-Z][a-z]{2} \d{1,2}, \d{4} \d{1,2}:\d{2}[ap]m$', linha) and len(linha) < 25):
                    linhas_limpas.append(linha)
    
    return '\n'.join(linhas_limpas)

def identificar_autor_avancado(driver, post_id):
    """Identifica autor usando JavaScript"""
    try:
        script = f"""
        var postElement = document.getElementById('{post_id}');
        var author = '';
        
        if (postElement) {{
            var parent = postElement.parentElement;
            for (var i = 0; i < 5 && parent; i++) {{
                var memberLinks = parent.querySelectorAll('a[href*="/member/"]');
                for (var j = 0; j < memberLinks.length; j++) {{
                    var link = memberLinks[j];
                    var text = link.textContent.trim();
                    if (text && text.length < 30 && 
                        !text.toLowerCase().includes('view profile') &&
                        !text.toLowerCase().includes('send message')) {{
                        author = text;
                        break;
                    }}
                }}
                if (author) break;
                parent = parent.parentElement;
            }}
        }}
        
        return author;
        """
        
        autor = driver.execute_script(script)
        return autor if autor else "N√£o identificado"
        
    except:
        return "N√£o identificado"

def baixar_imagens_pagina(post_elemento, session, pagina_num, post_num):
    """Baixa imagens de um post espec√≠fico"""
    imagens_info = []
    imagens_baixadas = []
    
    pasta_pagina = os.path.join(OUTPUT_DIR, 'imagens_por_pagina', f'pagina_{pagina_num}')
    os.makedirs(pasta_pagina, exist_ok=True)
    
    for i, img in enumerate(post_elemento.find_all('img', src=True)):
        src_original = img.get('src')
        if src_original and 'attachment' in src_original:
            
            src_corrigida = src_original.replace('/thumbnail', '')
            if src_corrigida.startswith('/'):
                src_corrigida = 'https://www.forexfactory.com' + src_corrigida
            
            nome_arquivo = f"pagina_{pagina_num}_post_{post_num}_img_{i+1}.jpg"
            caminho_arquivo = os.path.join(pasta_pagina, nome_arquivo)
            
            try:
                response = session.get(src_corrigida, timeout=10)
                if response.status_code == 200:
                    with open(caminho_arquivo, 'wb') as f:
                        f.write(response.content)
                    
                    imagens_baixadas.append({
                        'nome_arquivo': nome_arquivo,
                        'caminho_local': caminho_arquivo,
                        'url_original': src_original,
                        'url_corrigida': src_corrigida,
                        'tamanho_bytes': len(response.content)
                    })
                    
                    print(f"    ‚úÖ Imagem: {nome_arquivo}")
                else:
                    print(f"    ‚ùå Erro {response.status_code}: {nome_arquivo}")
                    
            except Exception as e:
                print(f"    ‚ùå Erro ao baixar {nome_arquivo}: {e}")
            
            imagens_info.append({
                'url_original': src_original,
                'url_corrigida': src_corrigida,
                'nome_arquivo': nome_arquivo,
                'baixada': len(imagens_baixadas) > 0 and imagens_baixadas[-1]['nome_arquivo'] == nome_arquivo
            })
    
    return imagens_info, imagens_baixadas

def processar_pagina(driver, session, pagina_num, total_paginas):
    """Processa uma p√°gina espec√≠fica do t√≥pico"""
    print(f"\nüìÑ PROCESSANDO P√ÅGINA {pagina_num}/{total_paginas}")
    print("=" * 50)
    
    html = driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    
    posts_elementos = soup.select('div.threadpost-content[id*="td_post_"]')
    print(f"‚úÖ Encontrados {len(posts_elementos)} posts na p√°gina {pagina_num}")
    
    posts_pagina = []
    posts_processados = set()
    
    for i, post_elemento in enumerate(posts_elementos):
        try:
            print(f"  üìù Processando post {i+1}...")
            
            conteudo = extrair_conteudo_post(post_elemento)
            
            if len(conteudo) < 30:
                print(f"    ‚è≠Ô∏è  Ignorado: muito pequeno ({len(conteudo)} chars)")
                continue
            
            hash_conteudo = hash(conteudo[:150])
            if hash_conteudo in posts_processados:
                print(f"    ‚è≠Ô∏è  Ignorado: duplicado")
                continue
            posts_processados.add(hash_conteudo)
            
            post_id = post_elemento.get('id', '')
            autor = identificar_autor_avancado(driver, post_id)
            
            imagens_info, imagens_baixadas = baixar_imagens_pagina(
                post_elemento, session, pagina_num, len(posts_pagina) + 1
            )
            
            anexos = []
            for link in post_elemento.find_all('a', href=True):
                href = link.get('href')
                texto = link.get_text().strip()
                if href and 'attachment' in href and texto and len(texto) > 3:
                    if href.startswith('/'):
                        href = 'https://www.forexfactory.com' + href
                    anexos.append({
                        'nome': texto,
                        'url': href
                    })
            
            post_info = {
                'numero_na_pagina': len(posts_pagina) + 1,
                'numero_global': None,
                'autor': autor,
                'data': "N√£o identificada",
                'conteudo': conteudo,
                'conteudo_tamanho': len(conteudo),
                'imagens_info': imagens_info,
                'imagens_baixadas': imagens_baixadas,
                'anexos': anexos,
                'numero_imagens': len(imagens_info),
                'numero_imagens_baixadas': len(imagens_baixadas),
                'numero_anexos': len(anexos),
                'post_id': post_id,
                'pagina': pagina_num
            }
            
            posts_pagina.append(post_info)
            
            preview = conteudo[:80].replace('\n', ' ')
            print(f"    ‚úÖ {autor}: '{preview}...' ({len(conteudo)} chars, {len(imagens_baixadas)} imgs)")
            
        except Exception as e:
            print(f"    ‚ùå Erro no post {i+1}: {e}")
            continue
    
    arquivo_pagina = os.path.join(OUTPUT_DIR, 'json_por_pagina', f'pagina_{pagina_num}.json')
    
    dados_pagina = {
        'pagina': pagina_num,
        'total_paginas': total_paginas,
        'url': driver.current_url,
        'timestamp': datetime.now().isoformat(),
        'posts_encontrados': len(posts_elementos),
        'posts_extraidos': len(posts_pagina),
        'posts': posts_pagina
    }
    
    with open(arquivo_pagina, 'w', encoding='utf-8') as f:
        json.dump(dados_pagina, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ P√°gina {pagina_num} salva: {len(posts_pagina)} posts extra√≠dos")
    
    return dados_pagina

def gerar_resumo_final(todas_paginas, pagina_inicio, pagina_fim):
    """Gera resumo final do range extra√≠do"""
    print(f"\nüìä GERANDO RESUMO FINAL...")
    
    total_posts = 0
    total_imagens = 0
    total_anexos = 0
    autores_unicos = set()
    posts_por_autor = {}
    
    numero_global = 1
    
    for pagina_dados in todas_paginas:
        for post in pagina_dados['posts']:
            post['numero_global'] = numero_global
            numero_global += 1
            
            total_posts += 1
            total_imagens += post['numero_imagens_baixadas']
            total_anexos += post['numero_anexos']
            
            autor = post['autor']
            autores_unicos.add(autor)
            
            if autor not in posts_por_autor:
                posts_por_autor[autor] = 0
            posts_por_autor[autor] += 1
    
    resumo = {
        'topico_url': THREAD_URL,
        'timestamp_extracao': datetime.now().isoformat(),
        'range_extraido': {
            'pagina_inicio': pagina_inicio,
            'pagina_fim': pagina_fim,
            'total_paginas_extraidas': len(todas_paginas)
        },
        'estatisticas': {
            'total_paginas': len(todas_paginas),
            'total_posts': total_posts,
            'total_imagens_baixadas': total_imagens,
            'total_anexos': total_anexos,
            'autores_unicos': len(autores_unicos),
            'posts_por_autor': posts_por_autor
        },
        'estrutura_arquivos': {
            'json_por_pagina': f"{OUTPUT_DIR}/json_por_pagina/",
            'imagens_por_pagina': f"{OUTPUT_DIR}/imagens_por_pagina/",
            'resumo_completo': f"{OUTPUT_DIR}/resumos/topico_range.json"
        },
        'paginas': [
            {
                'pagina': p['pagina'],
                'posts': len(p['posts']),
                'url': p['url']
            } for p in todas_paginas
        ]
    }
    
    arquivo_resumo = os.path.join(OUTPUT_DIR, 'resumos', 'resumo_range.json')
    with open(arquivo_resumo, 'w', encoding='utf-8') as f:
        json.dump(resumo, f, ensure_ascii=False, indent=2)
    
    arquivo_completo = os.path.join(OUTPUT_DIR, 'resumos', 'topico_range.json')
    with open(arquivo_completo, 'w', encoding='utf-8') as f:
        json.dump(todas_paginas, f, ensure_ascii=False, indent=2)
    
    return resumo

def main():
    """Fun√ß√£o principal - extra√ß√£o com range customiz√°vel"""
    
    print("\nüöÄ EXTRATOR FOREXFACTORY - RANGE DE P√ÅGINAS")
    print("=" * 65)
    
    print(f"\nüìã FUNCIONALIDADES:")
    print("1. ‚úÖ Escolher QUANTIDADE de p√°ginas (ex: 15, 100)")
    print("2. ‚úÖ Escolher RANGE de p√°ginas (ex: 1-10, 5-25)")
    print("3. ‚úÖ Extrair TODAS as p√°ginas")
    print("4. ‚úÖ Organiza√ß√£o por P√ÅGINA (posts + imagens)")
    print("5. ‚úÖ Resumo final com estat√≠sticas")
    
    criar_estrutura_diretorios()
    
    print(f"\nüîß Iniciando Chrome...")
    try:
        options = webdriver.ChromeOptions()
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        print("‚úÖ Chrome iniciado!")
        
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return
    
    try:
        print(f"\nüåê Abrindo ForexFactory...")
        driver.get('https://www.forexfactory.com/')
        
        print(f"\n" + "="*50)
        print(f"üéØ FA√áA LOGIN E NAVEGUE PARA A PRIMEIRA P√ÅGINA:")
        print(f"LOGIN: {USERNAME} / {PASSWORD}")
        print(f"URL: {THREAD_URL}")
        print(f"="*50)
        
        input(f"\n‚è≥ Pressione ENTER quando estiver na PRIMEIRA p√°gina: ")
        
        print(f"\nüç™ Criando sess√£o com cookies...")
        session = criar_sessao_com_cookies(driver)
        
        print(f"\nüîç Detectando n√∫mero total de p√°ginas...")
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        total_paginas_disponiveis = detectar_total_paginas(soup)
        
        # SOLICITAR RANGE AO USU√ÅRIO
        pagina_inicio, pagina_fim = solicitar_range_paginas(total_paginas_disponiveis)
        
        quantidade_extrair = pagina_fim - pagina_inicio + 1
        
        print(f"\nüéØ CONFIGURA√á√ÉO FINAL:")
        print(f"   üìä Total dispon√≠vel: {total_paginas_disponiveis} p√°ginas")
        print(f"   üì• Extrair: P√°ginas {pagina_inicio} at√© {pagina_fim}")
        print(f"   üìù Quantidade: {quantidade_extrair} p√°ginas")
        
        confirmacao = input(f"\n‚ñ∂Ô∏è  Iniciar extra√ß√£o? (ENTER para SIM, 'n' para N√ÉO): ").strip()
        if confirmacao.lower() in ['n', 'no', 'nao']:
            print("‚ùå Extra√ß√£o cancelada")
            return
        
        # PROCESSAR O RANGE SELECIONADO
        todas_paginas = []
        
        for pagina_num in range(pagina_inicio, pagina_fim + 1):
            try:
                if pagina_num > pagina_inicio:
                    url_pagina = construir_url_pagina(THREAD_URL, pagina_num)
                    print(f"\nüß≠ Navegando para p√°gina {pagina_num}: {url_pagina}")
                    driver.get(url_pagina)
                    time.sleep(2)
                
                dados_pagina = processar_pagina(driver, session, pagina_num, pagina_fim)
                todas_paginas.append(dados_pagina)
                
                if pagina_num < pagina_fim:
                    time.sleep(1)
                
            except Exception as e:
                print(f"‚ùå Erro na p√°gina {pagina_num}: {e}")
                continue
        
        resumo = gerar_resumo_final(todas_paginas, pagina_inicio, pagina_fim)
        
        print(f"\n" + "="*60)
        print(f"üéâ EXTRA√á√ÉO COMPLETA FINALIZADA!")
        print(f"="*60)
        print(f"üìä ESTAT√çSTICAS FINAIS:")
        print(f"  Range extra√≠do: P√°ginas {pagina_inicio} at√© {pagina_fim}")
        print(f"  P√°ginas processadas: {resumo['estatisticas']['total_paginas']}")
        print(f"  Posts extra√≠dos: {resumo['estatisticas']['total_posts']}")
        print(f"  Imagens baixadas: {resumo['estatisticas']['total_imagens_baixadas']}")
        print(f"  Anexos encontrados: {resumo['estatisticas']['total_anexos']}")
        print(f"  Autores √∫nicos: {resumo['estatisticas']['autores_unicos']}")
        
        print(f"\nüìÅ ARQUIVOS CRIADOS:")
        print(f"  üìÑ JSON por p√°gina: {OUTPUT_DIR}/json_por_pagina/")
        print(f"  üñºÔ∏è  Imagens por p√°gina: {OUTPUT_DIR}/imagens_por_pagina/")
        print(f"  üìä Resumos: {OUTPUT_DIR}/resumos/")
        
        print(f"\nüèÜ RANGE DE P√ÅGINAS EXTRA√çDO COM SUCESSO!")
        
    except Exception as e:
        print(f"‚ùå Erro geral: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        try:
            escolha = input(f"\nüîí Fechar Chrome? (s/N): ").strip().lower()
            if escolha.startswith('s'):
                driver.quit()
                print("‚úÖ Chrome fechado")
            else:
                print("‚úÖ Chrome mantido aberto")
        except:
            pass

if __name__ == "__main__":
    main()
